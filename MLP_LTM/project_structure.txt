.
├── _Deprecated
├── app
│   ├── __init__.py
│   ├── agent.py
│   ├── api.py
│   ├── config.py
│   ├── db
│   │   ├── __init__.py
│   │   ├── memory_database.py
│   │   └── memory_manager.py
│   ├── services
│   │   ├── embedding_service.py
│   │   ├── memory_linker.py
│   │   └── memory_retriever.py
│   └── utils
│       ├── __init__.py
│       └── logging.py
├── data
│   └── memories.db
├── logging_config.yaml
├── logs
│   └── app.log
├── requirements.txt
└── run.py

File Contents:

-e 
File: ./app/agent.py

# app/agent.py
import json
import re
from typing import List, Optional
from together import Together
from app.db.memory_manager import MemoryManager
from app.config import config
from app.utils.logging import get_logger

logger = get_logger('custom')
chat_logger = get_logger('chat')

class Agent:
    def __init__(self, api_key: str, memory_manager: MemoryManager):
        self.together_client = Together(api_key=api_key)
        self.memory_manager = memory_manager

    async def process_query(self, query: str) -> str:
        try:
            if self._is_trivia_request(query):
                return await self._process_trivia_request(query)
            
            memory_id = await self.memory_manager.create_memory_with_query(query)
            
            relevant_memories = await self._retrieve_relevant_memories(query)
            response = await self._generate_response(query, relevant_memories)
            
            await self.memory_manager.update_memory_with_response(memory_id, response)
            
            return response
        except Exception as e:
            logger.error(f"Error processing query: {str(e)}", exc_info=True)
            raise

    def _is_trivia_request(self, query: str) -> bool:
        pattern = r'^\s*Here are some trivia questions and answers for you to process\.'
        return bool(re.match(pattern, query, re.IGNORECASE))

    async def _process_trivia_request(self, query: str) -> str:
        try:
            answers = re.findall(r'\bAnswer:\s*(.+?)(?=\n|$)', query, re.IGNORECASE)
            return json.dumps(answers)
        except Exception as e:
            logger.error(f"Error processing trivia request: {str(e)}", exc_info=True)
            raise

    async def _retrieve_relevant_memories(self, query: str) -> List[str]:
        try:
            relevant_memories = await self.memory_manager.get_relevant_memories(query, top_k=5)
            return relevant_memories
        except Exception as e:
            logger.error(f"Error retrieving relevant memories: {str(e)}", exc_info=True)
            raise

    async def _generate_response(self, query: str, relevant_memories: List[str]) -> str:
        try:
            prompt = self._construct_prompt(query, relevant_memories)
            chat_logger.info(f"Generated prompt: {prompt}")
            
            response = self.together_client.chat.completions.create(
                messages=[{"role": "user", "content": prompt}],
                model=config.MODEL_NAME,
            )
            chat_logger.info(f"API response: {response}")
            
            return response.choices[0].message.content
        except Exception as e:
            logger.error(f"Error generating response: {str(e)}", exc_info=True)
            raise

    def _construct_prompt(self, query: str, relevant_memories: List[str]) -> str:
        memory_context = "\n".join([f"- {memory}" for memory in relevant_memories])
        return f"""You are an advanced AI assistant with access to a database of past interactions and knowledge. Your task is to provide a relevant, informative, and logically sound response to the given query. Follow these guidelines:

    1. Context Understanding:
    - The following memories have been retrieved based on their relevance to the current query.
    - Each memory is formatted as: "<timestamp> <past_query>:<past_response>"
    - Use these memories to inform your response, but do not repeat them verbatim.

    Retrieved Memories:
    {memory_context}

    2. Query Analysis:
    - Carefully analyze the query to understand its main points, implicit assumptions, and potential complexities.
    - If the query is ambiguous or lacks crucial information, state your assumptions clearly in your response.

    3. Logical Reasoning:
    - Apply deductive, inductive, and abductive reasoning as appropriate to the query.
    - Break down complex problems into smaller, manageable parts if necessary.
    - Clearly explain your thought process and the steps you take to arrive at your conclusion.

    4. Critical Thinking:
    - Consider multiple perspectives and potential counterarguments.
    - Evaluate the reliability and relevance of the information from the retrieved memories.
    - Highlight any uncertainties or limitations in your response.

    5. Response Formulation:
    - Provide a clear, concise, and well-structured response.
    - Use examples, analogies, or hypothetical scenarios to illustrate complex concepts if appropriate.
    - If the query requires a specific format (e.g., a list, a step-by-step guide, or a numerical answer), adhere to that format.

    6. Ethical Considerations:
    - Ensure your response is ethical, unbiased, and respectful.
    - If the query touches on sensitive topics, approach them with care and objectivity.

    Now, please respond to the following query:

    Query: {query}

    Response:"""
    
-e 
File: ./app/api.py

# app/api.py
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from app.agent import Agent
from app.db.memory_manager import MemoryManager
from app.config import config
from app.utils.logging import get_logger

app = FastAPI()
logger = get_logger('custom')

class QueryRequest(BaseModel):
    query: str

class QueryResponse(BaseModel):
    response: str

try:
    memory_manager = MemoryManager(config.DATABASE_URL)
    memory_manager.initialize()
    agent = Agent(config.TOGETHER_API_KEY, memory_manager)
except Exception as e:
    logger.error(f"Error initializing application: {str(e)}", exc_info=True)
    raise

@app.post("/query", response_model=QueryResponse)
async def query_endpoint(request: QueryRequest):
    try:
        logger.info(f"Received query: {request.query}")
        response = await agent.process_query(request.query)
        logger.info(f"Query processed successfully")
        return QueryResponse(response=response)
    except Exception as e:
        logger.error(f"Error processing query: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"An error occurred while processing the query")

@app.get("/health")
async def health_check():
    return {"status": "ok"}-e 
File: ./app/config.py

# app/config.py
import os
from dotenv import load_dotenv
from pydantic import BaseSettings, Field

load_dotenv()

class Config(BaseSettings):
    TOGETHER_API_KEY: str = Field(..., env="TOGETHER_API_KEY")
    DATABASE_URL: str = 'sqlite:///./data/memories.db'
    LOG_FILE_MAIN: str = './logs/app.log'
    LOG_FILE_CUSTOM: str = './logs/custom.log'
    LOG_FILE_CHAT: str = './logs/chat.log'
    LOG_LEVEL: str = Field(default="INFO", env="LOG_LEVEL")
    MODEL_NAME: str = "meta-llama/Llama-3-70b-chat-hf"

    MEMORY_LINKING: dict = {
        'enabled': True,
        'similarity_threshold': 0.8,
        'max_links_per_memory': None,  # None means infinite
        'query_only_linking': False,
        'keyword_matching': {
            'enabled': False,
            'threshold': 0.7
        }
    }

    EMBEDDING: dict = {
        'model': "text-embedding-ada-002",
        'dimensions': 1536  # Dimensions for the chosen embedding model
    }

    RETRIEVAL: dict = {
        'top_k': None,  # None means retrieve all relevant memories
        'min_similarity': 0.8
    }

    MEMORY_FORMATTING: dict = {
        'timestamp_format': '%Y-%m-%d %H:%M:%S'
    }

    class Config:
        env_file = ".env"

config = Config()

-e 
File: ./app/db/memory_database.py

# app/db/memory_database.py
from sqlalchemy import create_engine, Column, Integer, String, Table, ForeignKey
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker, relationship, Session
from contextlib import contextmanager
from app.config import config
from app.utils.logging import get_logger
from typing import List, Optional
import numpy as np
from datetime import datetime

logger = get_logger('custom')

Base = declarative_base()

memory_links = Table('memory_links', Base.metadata,
    Column('id', Integer, primary_key=True),
    Column('source_id', Integer, ForeignKey('memories.id')),
    Column('target_id', Integer, ForeignKey('memories.id'))
)

class Memory(Base):
    __tablename__ = 'memories'

    id = Column(Integer, primary_key=True)
    query = Column(String)
    response = Column(String)
    query_embedding = Column(String)  # Store as comma-separated string
    response_embedding = Column(String)  # Store as comma-separated string
    timestamp = Column(String)  # Store as string in format '%Y-%m-%d %H:%M:%S'

    links = relationship('Memory', secondary=memory_links,
                         primaryjoin=id==memory_links.c.source_id,
                         secondaryjoin=id==memory_links.c.target_id)

class MemoryDatabase:
    def __init__(self, db_url: str):
        self.engine = create_engine(db_url)
        self.SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=self.engine)

    def initialize(self):
        try:
            Base.metadata.create_all(bind=self.engine)
            logger.info("Database initialized successfully")
        except Exception as e:
            logger.error(f"Error initializing database: {str(e)}", exc_info=True)
            raise

    @contextmanager
    def get_db(self):
        db = self.SessionLocal()
        try:
            yield db
        finally:
            db.close()

    def create_memory(self, query: str, query_embedding: np.ndarray) -> int:
        try:
            current_time = datetime.now().strftime(config.MEMORY_FORMATTING['timestamp_format'])
            with self.get_db() as db:
                new_memory = Memory(
                    query=query,
                    query_embedding=','.join(map(str, query_embedding)),
                    timestamp=current_time
                )
                db.add(new_memory)
                db.commit()
                db.refresh(new_memory)
                logger.info(f"Memory created with ID: {new_memory.id}")
                return new_memory.id
        except Exception as e:
            logger.error(f"Error creating memory: {str(e)}", exc_info=True)
            raise

    def update_memory_response(self, memory_id: int, response: str, response_embedding: np.ndarray):
        try:
            with self.get_db() as db:
                memory = db.query(Memory).filter(Memory.id == memory_id).first()
                if memory is None:
                    raise ValueError(f"No memory found with ID {memory_id}")
                memory.response = response
                memory.response_embedding = ','.join(map(str, response_embedding))
                db.commit()
                logger.info(f"Memory ID {memory_id} updated with response")
        except Exception as e:
            logger.error(f"Error updating memory response: {str(e)}", exc_info=True)
            raise

    def get_all_memories(self) -> List[Memory]:
        try:
            with self.get_db() as db:
                memories = db.query(Memory).all()
                logger.info(f"Retrieved {len(memories)} memories")
                return memories
        except Exception as e:
            logger.error(f"Error retrieving all memories: {str(e)}", exc_info=True)
            raise

    def add_link(self, source_id: int, target_id: int):
        try:
            with self.get_db() as db:
                source_memory = db.query(Memory).filter(Memory.id == source_id).first()
                target_memory = db.query(Memory).filter(Memory.id == target_id).first()
                if source_memory is None or target_memory is None:
                    raise ValueError(f"Invalid memory IDs: {source_id}, {target_id}")
                source_memory.links.append(target_memory)
                db.commit()
                logger.info(f"Link added between memories {source_id} and {target_id}")
        except Exception as e:
            logger.error(f"Error adding link between memories: {str(e)}", exc_info=True)
            raise
            
-e 
File: ./app/db/memory_manager.py

# app/db/memory_manager.py
from app.db.memory_database import MemoryDatabase
from app.services.embedding_service import EmbeddingService
from app.services.memory_linker import MemoryLinker
from app.services.memory_retriever import MemoryRetriever
from app.config import config
from app.utils.logging import get_logger
from typing import List

logger = get_logger('custom')

class MemoryManager:
    def __init__(self, db_url: str):
        self.memory_db = MemoryDatabase(db_url)
        self.embedding_service = EmbeddingService()
        self.memory_linker = MemoryLinker(self.memory_db, self.embedding_service)
        self.memory_retriever = MemoryRetriever(self.memory_db, self.embedding_service)

    def initialize(self):
        try:
            self.memory_db.initialize()
            logger.info("MemoryManager initialized successfully")
        except Exception as e:
            logger.error(f"Error initializing MemoryManager: {str(e)}", exc_info=True)
            raise

    async def create_memory_with_query(self, query: str) -> int:
        try:
            logger.debug(f"Creating new memory with query: {query[:50]}...")
            query_embedding = await self.embedding_service.get_embedding(query)
            memory_id = self.memory_db.create_memory(query, query_embedding)
            logger.info(f"Memory created with query: ID {memory_id}")
            return memory_id
        except Exception as e:
            logger.error(f"Error creating memory with query: {str(e)}", exc_info=True)
            raise

    async def update_memory_with_response(self, memory_id: int, response: str):
        try:
            logger.debug(f"Updating memory ID {memory_id} with response: {response[:50]}...")
            response_embedding = await self.embedding_service.get_embedding(response)
            self.memory_db.update_memory_response(memory_id, response, response_embedding)
            
            if config.MEMORY_LINKING['enabled']:
                memory = self.memory_db.get_memory(memory_id)
                self.memory_linker.update_links(memory)
            
            logger.info(f"Memory ID {memory_id} updated with response")
        except Exception as e:
            logger.error(f"Error updating memory with response: {str(e)}", exc_info=True)
            raise

    async def get_relevant_memories(self, query: str, top_k: int = None) -> List[str]:
        try:
            return await self.memory_retriever.get_relevant_memories(query, top_k)
        except Exception as e:
            logger.error(f"Error getting relevant memories: {str(e)}", exc_info=True)
            raise
-e 
File: ./app/services/embedding_service.py

# app/services/embedding_service.py
from openai import AsyncOpenAI
import numpy as np
from app.config import config
from app.utils.logging import get_logger
import os

logger = get_logger('custom')

class EmbeddingService:
    def __init__(self):
        openai_api_key = os.getenv("OPENAI_API_KEY")
        if not openai_api_key:
            raise ValueError("OPENAI_API_KEY environment variable is not set")
        self.openai_client = AsyncOpenAI(api_key=openai_api_key)

    async def get_embedding(self, text: str) -> np.ndarray:
        try:
            logger.debug("Generating embedding using OpenAI")
            response = await self.openai_client.embeddings.create(
                input=[text],
                model=config.EMBEDDING['model']
            )
            embedding = response.data[0].embedding
            logger.debug("Embedding generated successfully")
            return np.array(embedding, dtype=np.float32)
        except Exception as e:
            logger.error(f"Error generating embedding: {str(e)}", exc_info=True)
            raise

    def cosine_similarity(self, a: np.ndarray, b: np.ndarray) -> float:
        return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))
        
-e 
File: ./app/services/memory_linker.py

# app/services/memory_linker.py
from app.db.memory_database import MemoryDatabase, Memory
from app.services.embedding_service import EmbeddingService
from app.config import config
from app.utils.logging import get_logger
from typing import List
import numpy as np

logger = get_logger('custom')

class MemoryLinker:
    def __init__(self, memory_db: MemoryDatabase, embedding_service: EmbeddingService):
        self.memory_db = memory_db
        self.embedding_service = embedding_service

    def update_links(self, memory: Memory):
        try:
            logger.debug(f"Updating links for memory: ID {memory.id}")
            all_memories = self.memory_db.get_all_memories()
            links_count = 0
            for other_memory in all_memories:
                if other_memory.id != memory.id and self._should_link(memory, other_memory):
                    self.memory_db.add_link(memory.id, other_memory.id)
                    links_count += 1
                    logger.debug(f"Linked memory ID {other_memory.id} to memory ID {memory.id}")
                
                if config.MEMORY_LINKING['max_links_per_memory'] is not None and links_count >= config.MEMORY_LINKING['max_links_per_memory']:
                    break
            logger.info(f"Updated links for memory ID {memory.id}. Total links: {links_count}")
        except Exception as e:
            logger.error(f"Error updating links: {str(e)}", exc_info=True)
            raise

    def _should_link(self, memory1: Memory, memory2: Memory) -> bool:
        query_similarity = self.embedding_service.cosine_similarity(
            np.fromstring(memory1.query_embedding, sep=','),
            np.fromstring(memory2.query_embedding, sep=',')
        )
        response_similarity = 0
        if memory1.response_embedding and memory2.response_embedding:
            response_similarity = self.embedding_service.cosine_similarity(
                np.fromstring(memory1.response_embedding, sep=','),
                np.fromstring(memory2.response_embedding, sep=',')
            )
        
        max_similarity = max(query_similarity, response_similarity)
        
        if max_similarity > config.MEMORY_LINKING['similarity_threshold']:
            return True
        
        if config.MEMORY_LINKING['keyword_matching']['enabled']:
            keyword_similarity = self._keyword_similarity(memory1.query + memory1.response, memory2.query + memory2.response)
            if keyword_similarity > config.MEMORY_LINKING['keyword_matching']['threshold']:
                return True
        
        return False

    def _keyword_similarity(self, content1: str, content2: str) -> float:
        # This is a placeholder function for keyword matching
        # Implement your keyword matching algorithm here
        # Return a similarity score between 0 and 1
        return 0.0

    def update_links_for_query(self, query_embedding: np.ndarray, relevant_memories: List[Memory]):
        logger.debug("Updating links for query-based retrieval")
        for memory in relevant_memories:
            similarity = self.embedding_service.cosine_similarity(
                query_embedding,
                np.fromstring(memory.query_embedding, sep=',')
            )
            if similarity > config.MEMORY_LINKING['similarity_threshold']:
                # Here you would implement the logic to create links based on the query
                # This might involve creating a temporary memory object for the query
                # or updating the links of the retrieved memories
                pass
                
-e 
File: ./app/services/memory_retriever.py

# app/services/memory_retriever.py
from app.db.memory_database import MemoryDatabase, Memory
from app.services.embedding_service import EmbeddingService
from app.config import config
from app.utils.logging import get_logger
from typing import List, Tuple
import numpy as np
from datetime import datetime

logger = get_logger('custom')

class MemoryRetriever:
    def __init__(self, memory_db: MemoryDatabase, embedding_service: EmbeddingService):
        self.memory_db = memory_db
        self.embedding_service = embedding_service

    async def get_relevant_memories(self, query: str, top_k: int = None) -> List[str]:
        try:
            logger.debug(f"Retrieving relevant memories for query: {query[:50]}...")
            query_embedding = await self.embedding_service.get_embedding(query)
            memories = self.memory_db.get_all_memories()
            
            similarities = self._calculate_similarities(memories, query_embedding)
            sorted_memories = sorted(zip(memories, similarities), key=lambda x: x[1], reverse=True)
            
            result = [(m, sim) for m, sim in sorted_memories if sim >= config.RETRIEVAL['min_similarity']]
            
            if config.MEMORY_LINKING['enabled']:
                result = self._include_linked_memories(result, query_embedding)
            
            formatted_memories = self._format_memories(result)
            
            total_matching_memories = len(formatted_memories)
            
            if top_k is None:
                top_k = config.RETRIEVAL['top_k']
            
            if top_k is not None:
                formatted_memories = formatted_memories[:top_k]
            
            logger.info(f"Retrieved {len(formatted_memories)} out of {total_matching_memories} relevant unique memories")
            
            return formatted_memories
        except Exception as e:
            logger.error(f"Error retrieving relevant memories: {str(e)}", exc_info=True)
            raise

    def _calculate_similarities(self, memories: List[Memory], query_embedding: np.ndarray) -> List[float]:
        return [
            max(
                self.embedding_service.cosine_similarity(query_embedding, np.fromstring(m.query_embedding, sep=',')),
                self.embedding_service.cosine_similarity(query_embedding, np.fromstring(m.response_embedding, sep=',')) if m.response_embedding else 0
            )
            for m in memories
        ]

    def _include_linked_memories(self, result: List[Tuple[Memory, float]], query_embedding: np.ndarray) -> List[Tuple[Memory, float]]:
        linked_memories = set()
        for memory, _ in result:
            for linked_memory in memory.links:
                if linked_memory not in [m for m, _ in result]:
                    linked_sim = max(
                        self.embedding_service.cosine_similarity(query_embedding, np.fromstring(linked_memory.query_embedding, sep=',')),
                        self.embedding_service.cosine_similarity(query_embedding, np.fromstring(linked_memory.response_embedding, sep=',')) if linked_memory.response_embedding else 0
                    )
                    if linked_sim >= config.RETRIEVAL['min_similarity']:
                        linked_memories.add((linked_memory, linked_sim))
        
        result.extend(linked_memories)
        return result

    def _format_memories(self, memories: List[Tuple[Memory, float]]) -> List[str]:
        unique_memories = {}
        for memory, sim in memories:
            if memory.id not in unique_memories:
                unique_memories[memory.id] = memory
        
        sorted_unique_memories = sorted(unique_memories.values(), key=lambda m: m.timestamp, reverse=True)
        
        formatted_memories = []
        for memory in sorted_unique_memories:
            try:
                timestamp = datetime.strptime(memory.timestamp, config.MEMORY_FORMATTING['timestamp_format'])
                formatted_timestamp = timestamp.strftime(config.MEMORY_FORMATTING['timestamp_format'])
            except (ValueError, TypeError):
                logger.warning(f"Invalid timestamp format for memory ID {memory.id}: {memory.timestamp}")
                formatted_timestamp = "Unknown Time"

            formatted_memory = f"{formatted_timestamp} {memory.query}:{memory.response}" if memory.response else f"{formatted_timestamp} {memory.query}:"
            formatted_memories.append(formatted_memory)
        
        return formatted_memories
        
-e 
File: ./app/utils/logging.py

# app/utils/logging.py
import logging
from logging.handlers import RotatingFileHandler
import os
from app.config import config

def setup_logger(name, log_file, level=logging.INFO):
    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    
    handler = RotatingFileHandler(log_file, maxBytes=10*1024*1024, backupCount=5)
    handler.setFormatter(formatter)

    logger = logging.getLogger(name)
    logger.setLevel(level)
    logger.addHandler(handler)

    return logger

# Setup loggers
main_logger = setup_logger('main', config.LOG_FILE_MAIN, level=config.LOG_LEVEL)
custom_logger = setup_logger('custom', config.LOG_FILE_CUSTOM, level=config.LOG_LEVEL)
chat_logger = setup_logger('chat', config.LOG_FILE_CHAT, level=config.LOG_LEVEL)

def get_logger(name: str):
    if name == 'chat':
        return chat_logger
    elif name == 'custom':
        return custom_logger
    else:
        return main_logger

-e 
File: ./logging_config.yaml

version: 1
disable_existing_loggers: False
formatters:
  default:
    format: '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
handlers:
  console:
    class: logging.StreamHandler
    level: INFO
    formatter: default
    stream: ext://sys.stdout
  file:
    class: logging.handlers.RotatingFileHandler
    level: DEBUG
    formatter: default
    filename: logs/app.log
    maxBytes: 10485760 # 10MB
    backupCount: 5
loggers:
  uvicorn:
    level: INFO
  uvicorn.access:
    level: INFO
root:
  level: DEBUG
  handlers: [console, file]
